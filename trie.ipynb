{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of Trie. Source: https://albertauyeung.github.io/2020/06/15/python-trie.html/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode(object):\n",
    "    \"\"\"\n",
    "    Trie Node\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, char):\n",
    "    \n",
    "        self.char = char\n",
    "        self.is_end = False\n",
    "        self.counter = 0\n",
    "        self.children = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trie(object):\n",
    "    \"\"\"\n",
    "    Trie object\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # head node is empty\n",
    "        \n",
    "        self.root = TrieNode(\"\")\n",
    "    \n",
    "    def insert(self, word):\n",
    "        \"\"\"Insert a word into the trie\"\"\"\n",
    "        node = self.root\n",
    "        \n",
    "        # Loop through each character in the word\n",
    "        # Check if there is no child containing the character, create a new child for the current node\n",
    "        for char in word:\n",
    "            if char in node.children:\n",
    "                node = node.children[char]\n",
    "            else:\n",
    "                # If a character is not found,\n",
    "                # create a new node in the trie\n",
    "                new_node = TrieNode(char)\n",
    "                node.children[char] = new_node\n",
    "                node = new_node\n",
    "        \n",
    "        # Mark the end of a word\n",
    "        node.is_end = True\n",
    "\n",
    "        # Increment the counter to indicate that we see this word once more\n",
    "        node.counter += 1\n",
    "    \n",
    "    def dfs(self, node, prefix):\n",
    "        \"\"\"\n",
    "        Depth-first search\n",
    "        \"\"\"\n",
    "        \n",
    "        if node.is_end:\n",
    "            self.output.append((prefix + node.char, node.counter))\n",
    "        \n",
    "        for child in node.children.values():\n",
    "            self.dfs(child, prefix + node.char)\n",
    "    \n",
    "    def query(self, x):\n",
    "        \"\"\"\n",
    "        Given input (prefix), retrieve all words stored in a trie\n",
    "        with that prefix. Sort the words by the number of times\n",
    "        the word has been inserted\n",
    "        \"\"\"\n",
    "        \n",
    "        self.output = []\n",
    "        node = self.root\n",
    "        \n",
    "        # check if prefix is in a trie\n",
    "        for char in x:\n",
    "            print(char)\n",
    "            if char in node.children:\n",
    "                node = node.children[char]\n",
    "            else:\n",
    "                return []\n",
    "        \n",
    "        self.dfs(node, x[:-1])\n",
    "        \n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w\n",
      "h\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('what', 1), ('where', 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Trie()\n",
    "t.insert(\"was\")\n",
    "t.insert(\"word\")\n",
    "t.insert(\"war\")\n",
    "t.insert(\"what\")\n",
    "t.insert(\"where\")\n",
    "t.insert(\"hello\")\n",
    "t.insert(\"high\")\n",
    "t.query(\"wh\")\n",
    "#[('what', 1), ('where', 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement**:\n",
    "\n",
    "We would like to implement search bar. We have a lot of lists of words (for example, news articles) and each of the list has random uuid. Our task is to find all instances of list id that would contain similar words. For example:\n",
    "\n",
    "Assume we have 3 lists `list_1 = ['wall', 'ball', 'hello']`, `list_2 = ['wall', 'well', 'name']`, `list_3 = ['well', 'smoke', 'wood']`.\n",
    "If we input `wa` we want to get id of list_1 and list_2.\n",
    "\n",
    "**How to do it?**\n",
    "\n",
    "First, we construct input dictionary: `{word1 = [ids,,], word2: [ids...]}` where keys are unique words. Given that, we could use `for` loop and find appropriate IDs. However, this is slow and inneficient. Other way is to use Trie!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_data.pickle', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_no_numbers = list(\n",
    "    map(lambda x: re.sub('\\d', '', x), test_data)\n",
    ")\n",
    "\n",
    "test_data_no_numbers = list(\n",
    "    map(lambda x: list(set(x.lower().split(';'))), test_data_no_numbers)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_lists_to_set(input_data: list) -> set:\n",
    "    \"\"\"\n",
    "    Given input list of lists of strings,\n",
    "    cast it to set with unique words only\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    for i in input_data:\n",
    "        temp += i.split(' ')\n",
    "    return list(set(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_no_numbers = list(\n",
    "    map(lambda x: list_of_lists_to_set(x), test_data_no_numbers)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Common Dictionary**\n",
    "\n",
    "We want to create the following data structure:\n",
    "\n",
    "```\n",
    "{\n",
    "    'word1': [uuid1, uuid2...],\n",
    "    'word2': [uuid1, uuid2...],\n",
    "}\n",
    "```\n",
    "\n",
    "In this data structure, we have unique words from all documents as keys\n",
    "and values are IDs of documents where they appear. Technically we could compute\n",
    "all possible combinations and then look that up which would give us O(1) time complexity but O(number of possible combinations) space complexity\n",
    "\n",
    "Given this structure, our search bar would work in the following way:\n",
    "\n",
    "User starts typing word (like \"hello\", we find all the articles that has word \"hello\" and show them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create intermediary dictionary:\n",
    "# {'id': [words], ...}\n",
    "\n",
    "intermediate = dict(zip([str(uuid.uuid4()) for _ in range(len(test_data_no_numbers))], test_data_no_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create set of all words from the articles\n",
    "all_words = []\n",
    "\n",
    "for a in test_data_no_numbers:\n",
    "    all_words += a\n",
    "all_words = set(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given all_words set, construct dictionary:\n",
    "# {word: [id1, id2],..}\n",
    "\n",
    "words_to_ids = {}\n",
    "\n",
    "for w in all_words:\n",
    "    ids = []\n",
    "    for k, v in intermediate.items():\n",
    "        if w in v:\n",
    "            ids.append(k)\n",
    "    words_to_ids[w] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_global_dictionary(\n",
    "    words_to_ids: dict,\n",
    "    ids_to_words: dict,\n",
    "    words: list\n",
    "):\n",
    "    \"\"\"\n",
    "    Test if words to ids dictionary\n",
    "    is correctly done by providing list\n",
    "    of test words\n",
    "    \"\"\"\n",
    "    \n",
    "    for w in words:\n",
    "        ids_to_test = words_to_ids[w]\n",
    "        for id_ in ids_to_test:\n",
    "            if w not in ids_to_words[id_]:\n",
    "                raise ValueError(f\"Word {w} not found!\")\n",
    "            else:\n",
    "                print(ids_to_words[id_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['twitter,', 'jewish', 'facebook,', 'beyond,', 'bed', 'museum,', 'bath']\n",
      "['iron', 'bath', 'works,']\n",
      "['city', 'bath', 'council,']\n",
      "['york', 'facebook,', 'oxford', 'school', 'bath', 'university,', 'of', 'medicine,', 'university']\n",
      "['iron', 'us', 'press,', 'works,', 'naval', 'bath', 'navy,', 'academy,', 'associated']\n",
      "['elemental', 'joy', 'facial', 'herbology', 'cleanse', 'oil,', 'bath', 'beatitude', 'cleansing', 'harmonising']\n",
      "['malaysia,', 'in', 'racquets', 'mayfair,', 'club', 'high', 'national', 'tree,', 'opera,', 'group', 'bath', 'of', 'court,', 'lion', 'english']\n",
      "['cross', 'church,', 'mackintosh', 'museum', 'at', 'albert', 'museum,', 'bath', 'of', 'glasgow,', 'queen', 'work,', 'university']\n",
      "['twitter,', 'neiman', 'facebook,', 'beyond,', 'soho', 'in', 'nordstrom,', 'bed', 'bag', 'diaper', 'marcus,', 'bath', 'solutions', 'dahlia,']\n",
      "['twitter,', 'deputy', 'tom', 'leader', 'oregon', 'state', 'university,', 'watson,', 'party', 'labour']\n",
      "['research', 'parnell,', 'development', 'tom']\n",
      "['church,', 'tom']\n",
      "['too', 'tom', 'school', 'hotel,', 'days,', 'brown', 'stafford']\n",
      "['district', 'inc,', 'textron', 'bell', 'court,', 'helicopter']\n",
      "['lifesaver', 'service,', 'rescue', 'helicopter', 'westpac']\n"
     ]
    }
   ],
   "source": [
    "test_global_dictionary(words_to_ids, intermediate, words=['bath', 'tom', 'helicopter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode(object):\n",
    "    \"\"\"\n",
    "    Trie Node\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, char):\n",
    "    \n",
    "        self.char = char\n",
    "        self.is_end = False\n",
    "        self.ids = []\n",
    "        self.children = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trie(object):\n",
    "    \"\"\"\n",
    "    Trie object\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # head node is empty\n",
    "        \n",
    "        self.root = TrieNode(\"\")\n",
    "    \n",
    "    def insert(self, word: str, ids: list):\n",
    "        \"\"\"Insert a word into the trie\"\"\"\n",
    "        node = self.root\n",
    "        \n",
    "        # Loop through each character in the word\n",
    "        # Check if there is no child containing the character, create a new child for the current node\n",
    "        for char in word:\n",
    "            if char in node.children:\n",
    "                node = node.children[char]\n",
    "                node.ids += ids\n",
    "            else:\n",
    "                # If a character is not found,\n",
    "                # create a new node in the trie\n",
    "                new_node = TrieNode(char)\n",
    "                node.children[char] = new_node\n",
    "                node = new_node\n",
    "                node.ids += ids\n",
    "        \n",
    "        # Mark the end of a word\n",
    "        node.is_end = True\n",
    "    \n",
    "    def dfs(self, node, prefix):\n",
    "        \"\"\"\n",
    "        Depth-first search\n",
    "        \"\"\"\n",
    "        \n",
    "        if node.is_end:\n",
    "            self.output.append((prefix + node.char, node.ids))\n",
    "        \n",
    "        for child in node.children.values():\n",
    "            self.dfs(child, prefix + node.char)\n",
    "    \n",
    "    def query(self, x):\n",
    "        \"\"\"\n",
    "        Given input (prefix), retrieve all words stored in a trie\n",
    "        with that prefix. Sort the words by the number of times\n",
    "        the word has been inserted\n",
    "        \"\"\"\n",
    "        \n",
    "        self.output = []\n",
    "        node = self.root\n",
    "        \n",
    "        # check if prefix is in a trie\n",
    "        for char in x:\n",
    "            if char in node.children:\n",
    "                node = node.children[char]\n",
    "            else:\n",
    "                return []\n",
    "        \n",
    "        self.dfs(node, x[:-1])\n",
    "        \n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Trie()\n",
    "\n",
    "for k, v in words_to_ids.items():\n",
    "    t.insert(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test alternate implementation\n",
    "query_result = []\n",
    "for k, v in words_to_ids.items():\n",
    "    if 'tom' in k:\n",
    "        query_result += v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tom',\n",
       "  ['e6efe78c-93f8-493a-861b-06a658f98a44',\n",
       "   '742b7772-26a0-4b54-8d7e-c2e302a4120c',\n",
       "   '76f5f33a-4f4e-4782-8d0d-acfce03b4fc1',\n",
       "   '04555399-a56a-4a39-8c3f-96e170774322',\n",
       "   '0eeefb49-6d4a-4b1e-9dd2-8bf5c0c0ef48',\n",
       "   '4f07b53c-7fa2-4412-8303-447efd261795',\n",
       "   'eea6bf6b-3dc6-4f90-8c50-7399d78ce024',\n",
       "   '29dd6fb7-668c-4bf9-8a9f-2fd63e5e2a45',\n",
       "   'bc899bf2-584e-488d-b16a-84329cd01e57',\n",
       "   '6212cced-d4a7-404a-8f28-990ba67b3a03',\n",
       "   'd37753d6-4987-45de-bf34-1133f5fbc0fa',\n",
       "   '7336cc4f-f308-45c0-b595-376f52e6207d',\n",
       "   'f33a34ea-53b6-48cb-820f-118c4b2e3460',\n",
       "   'facc2af4-7749-4c53-881c-8f3156c13bbb',\n",
       "   '370dfb02-089d-46a6-a8f0-89cebedca173',\n",
       "   'f7f7c2b7-5680-4665-b6b1-76b8aa68144d',\n",
       "   '3820403d-6f33-476f-b2cc-ed2de8683829',\n",
       "   'c5aa7075-139d-41af-a9c9-16392e7e9b12',\n",
       "   'ffcb2c3c-1c6a-422b-a47d-de96d79c5541',\n",
       "   '5822d848-5da0-4e32-9dcd-be87e5fb7c62',\n",
       "   'e550ca48-ea83-4429-8253-dcebf99ef021',\n",
       "   '083cabfb-3ee7-49f0-a7e9-5716d2897c06',\n",
       "   '3c7ef838-947c-4250-bd67-9181a2d9e0fb',\n",
       "   '1720c9b2-a8b4-46d1-8373-74244ebace35',\n",
       "   '5defa3d9-dd6f-4bdc-a82b-0cac335ec31d',\n",
       "   'c5aa7075-139d-41af-a9c9-16392e7e9b12',\n",
       "   '4ce469df-4f60-4ac6-9d8e-304d2b1c96f1',\n",
       "   'c80cdf45-1815-4649-adcb-f1d4f7e57058',\n",
       "   'f0b5cbdc-b3c9-4c7c-b697-af6c0774f372',\n",
       "   'e49a26de-99e8-4304-b12f-534b14136a26',\n",
       "   '28efb006-4d82-4800-aab8-cde072852815',\n",
       "   'f6de772b-8bf5-4041-90c3-d7445e987449',\n",
       "   '09cd57d1-6bbb-4f96-97b5-9b4a45eea37e']),\n",
       " ('tomas', ['e6efe78c-93f8-493a-861b-06a658f98a44']),\n",
       " ('tommy',\n",
       "  ['742b7772-26a0-4b54-8d7e-c2e302a4120c',\n",
       "   '76f5f33a-4f4e-4782-8d0d-acfce03b4fc1',\n",
       "   '04555399-a56a-4a39-8c3f-96e170774322',\n",
       "   '0eeefb49-6d4a-4b1e-9dd2-8bf5c0c0ef48',\n",
       "   '4f07b53c-7fa2-4412-8303-447efd261795',\n",
       "   'eea6bf6b-3dc6-4f90-8c50-7399d78ce024',\n",
       "   '29dd6fb7-668c-4bf9-8a9f-2fd63e5e2a45',\n",
       "   'bc899bf2-584e-488d-b16a-84329cd01e57',\n",
       "   '6212cced-d4a7-404a-8f28-990ba67b3a03',\n",
       "   'd37753d6-4987-45de-bf34-1133f5fbc0fa',\n",
       "   '7336cc4f-f308-45c0-b595-376f52e6207d',\n",
       "   'f33a34ea-53b6-48cb-820f-118c4b2e3460',\n",
       "   'facc2af4-7749-4c53-881c-8f3156c13bbb',\n",
       "   '370dfb02-089d-46a6-a8f0-89cebedca173',\n",
       "   'f7f7c2b7-5680-4665-b6b1-76b8aa68144d',\n",
       "   '3820403d-6f33-476f-b2cc-ed2de8683829',\n",
       "   'c5aa7075-139d-41af-a9c9-16392e7e9b12',\n",
       "   'ffcb2c3c-1c6a-422b-a47d-de96d79c5541',\n",
       "   '5822d848-5da0-4e32-9dcd-be87e5fb7c62',\n",
       "   'e550ca48-ea83-4429-8253-dcebf99ef021',\n",
       "   '083cabfb-3ee7-49f0-a7e9-5716d2897c06',\n",
       "   '3c7ef838-947c-4250-bd67-9181a2d9e0fb',\n",
       "   '1720c9b2-a8b4-46d1-8373-74244ebace35',\n",
       "   '5defa3d9-dd6f-4bdc-a82b-0cac335ec31d',\n",
       "   'c5aa7075-139d-41af-a9c9-16392e7e9b12',\n",
       "   '4ce469df-4f60-4ac6-9d8e-304d2b1c96f1',\n",
       "   'c80cdf45-1815-4649-adcb-f1d4f7e57058']),\n",
       " ('tommy,',\n",
       "  ['742b7772-26a0-4b54-8d7e-c2e302a4120c',\n",
       "   '76f5f33a-4f4e-4782-8d0d-acfce03b4fc1',\n",
       "   '04555399-a56a-4a39-8c3f-96e170774322',\n",
       "   '0eeefb49-6d4a-4b1e-9dd2-8bf5c0c0ef48',\n",
       "   '4f07b53c-7fa2-4412-8303-447efd261795',\n",
       "   'eea6bf6b-3dc6-4f90-8c50-7399d78ce024',\n",
       "   '29dd6fb7-668c-4bf9-8a9f-2fd63e5e2a45',\n",
       "   'bc899bf2-584e-488d-b16a-84329cd01e57',\n",
       "   '6212cced-d4a7-404a-8f28-990ba67b3a03',\n",
       "   'd37753d6-4987-45de-bf34-1133f5fbc0fa',\n",
       "   '7336cc4f-f308-45c0-b595-376f52e6207d',\n",
       "   'f33a34ea-53b6-48cb-820f-118c4b2e3460',\n",
       "   'facc2af4-7749-4c53-881c-8f3156c13bbb',\n",
       "   '370dfb02-089d-46a6-a8f0-89cebedca173',\n",
       "   'f7f7c2b7-5680-4665-b6b1-76b8aa68144d',\n",
       "   '3820403d-6f33-476f-b2cc-ed2de8683829',\n",
       "   'c5aa7075-139d-41af-a9c9-16392e7e9b12',\n",
       "   'ffcb2c3c-1c6a-422b-a47d-de96d79c5541',\n",
       "   '5822d848-5da0-4e32-9dcd-be87e5fb7c62',\n",
       "   'e550ca48-ea83-4429-8253-dcebf99ef021']),\n",
       " ('tom,', ['09cd57d1-6bbb-4f96-97b5-9b4a45eea37e'])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.query('tom')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pp37",
   "language": "python",
   "name": "pp37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
